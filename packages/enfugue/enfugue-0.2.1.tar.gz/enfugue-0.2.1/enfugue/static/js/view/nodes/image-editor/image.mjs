import{isEmpty}from"../../../base/helpers.mjs";import{ImageView,BackgroundImageView}from"../../image.mjs";import{ImageEditorScribbleNodeView}from"./scribble.mjs";import{FormView}from"../../forms/base.mjs";import{SelectInputView,CheckboxInputView,TextInputView,NumberInputView,FloatInputView}from"../../forms/input.mjs";class ImageColorSpaceInputView extends SelectInputView{static defaultOptions={invert:"White on Black"};static defaultValue="invert";static placeholder="Black on White";static allowEmpty=!0}class ControlNetInputView extends SelectInputView{static defaultValue="canny";static defaultOptions={canny:"Canny Edge Detection",hed:"Holistically-nested Edge Detection (HED)",pidi:"Soft Edge Detection (PIDI)",mlsd:"Mobile Line Segment Detection (MLSD)",line:"Line Art",anime:"Anime Line Art",scribble:"Scribble",depth:"Depth Detection (MiDaS)",normal:"Normal Detection (Estimate)",pose:"Pose Detection (OpenPose)"};static tooltip="The ControlNet to use depends on your input image. Unless otherwise specified, your input image will be processed through the appropriate algorithm for this ControlNet prior to diffusion.<br /><strong>Canny Edge</strong>: This network is trained on images and the edges of that image after having run through Canny Edge detection.<br /><strong>HED</strong>: Short for Holistically-Nested Edge Detection, this edge-detection algorithm is best used when the input image is too blurry or too noisy for Canny Edge detection.<br /><strong>Soft Edge Detection</strong>: Using a Pixel Difference Network, this edge-detection algorithm can be used in a wide array of applications.<br /><strong>MLSD</strong>: Short for Mobile Line Segment Detection, this edge-detection algorithm searches only for straight lines, and is best used for geometric or architectural images.<br /><strong>Line Art</strong>: This model is capable of rendering images to line art drawings. The controlnet was trained on the model output, this provides a great way to provide your own hand-drawn pieces as well as another means of edge detection.<br /><strong>Anime Line Art</strong>: This is similar to the above, but focusing specifically on anime style.<br /><strong>Scribble</strong>: This ControlNet was trained on a variant of the HED edge-detection algorithm, and is good for hand-drawn scribbles with thick, variable lines.<br /><strong>Depth</strong>: This uses Intel's MiDaS model to estimate monocular depth from a single image. This uses a greyscale image showing the distance from the camera to any given object.<br /><strong>Normal</strong>: Normal maps are similar to depth maps, but instead of using a greyscale depth, three sets of distance data is encoded into red, green and blue channels.<br /><strong>OpenPose</strong>: This AI model from the Carnegie Mellon University's Perceptual Computing Lab detects human limb, face and digit poses from an image. Using this data, you can generate different people in the same pose."}class ImageFitInputView extends SelectInputView{static defaultValue="actual";static defaultOptions={actual:"Actual Size",stretch:"Stretch",contain:"Contain",cover:"Cover"};static tooltip="Fit this image within it's container.<br /><strong>Actual</strong>: Do not manipulate the dimensions of the image, anchor it as specified in the frame.<br /><strong>Stretch</strong>: Force the image to fit within the frame, regardles sof original dimensions. When using this mode, anchor has no effect.<br /><strong>Contain</strong>: Scale the image so that it's largest dimension is contained within the frames bounds, adding negative space to fill the rest of the frame.<br /><strong>Cover</strong>: Scale the image so that it's smallest dimension is contained within the frame bounds, cropping the rest of the image as needed."}class ImageAnchorInputView extends SelectInputView{static defaultValue="top-left";static defaultOptions={"top-left":"Top Left","top-center":"Top Center","top-right":"Top Right","center-left":"Center Left","center-center":"Center Center","center-right":"Center Right","bottom-left":"Bottom Left","bottom-center":"Bottom Center","bottom-right":"Bottom Right"};static tooltip="When the size of the frame and the size of the image do not match, this will control where the image is placed. View the 'fit' field for more options to fit images in the frame."}class ImageEditorImageNodeOptionsFormView extends FormView{static fieldSets={Base:{fit:{label:"Image Fit",class:ImageFitInputView},anchor:{label:"Image Anchor",class:ImageAnchorInputView},inpaint:{label:"Use for Inpainting",class:CheckboxInputView,config:{tooltip:"When checked, you will be able to paint where on the image you wish for the AI to fill in details. Any gaps in the frame or transparency in the image will also be filled."}},infer:{label:"Use for Inference",class:CheckboxInputView,config:{tooltip:"When checked, use this image as input for primary diffusion. Inpainting will be performed first, filling any painted sections as well as gaps in the frame and transparency in the image."}},control:{label:"Use for Control",class:CheckboxInputView,config:{tooltip:"When checked, use this image as input for ControlNet. Inpainting will be performed first, filling any painted sections as well as gaps in the frame and transparency in the image.<br />Unless otherwise specified, your image will be processed using the appropriate algorithm for the chosen ControlNet."}}},Other:{scaleToModelSize:{label:"Scale to Model Size",class:CheckboxInputView,config:{tooltip:"When this has any dimension smaller than the size of the configured model, scale it up so it's smallest dimension is the same size as the model, then scale it down after diffusion.<br />This generally improves image quality in rectangular shapes, but can also result in ghosting and increased processing time.<br />This will have no effect if your node is larger than the model size in all dimensions.<br />If unchecked and your node is smaller than the model size, TensorRT will be disabled for this node."}},removeBackground:{label:"Remove Background",class:CheckboxInputView,config:{tooltip:"Before processing, run this image through an AI background removal process. If you are additionally inpainting, inferencing or using this image for ControlNet, that background will then be filled in within this frame. If you are not, that background will be filled when the overall canvas image is finally painted in."}}},Prompts:{prompt:{label:"Prompt",class:TextInputView,config:{tooltip:"This prompt will control what is in this frame. When left blank, the global prompt will be used."}},negativePrompt:{label:"Negative Prompt",class:TextInputView,config:{tooltip:"This prompt will control what is in not this frame. When left blank, the global negative prompt will be used."}}},Tweaks:{guidanceScale:{label:"Guidance Scale",class:FloatInputView,config:{min:0,max:100,step:.1,value:null,tooltip:"How closely to follow the text prompt; high values result in high-contrast images closely adhering to your text, low values result in low-contrast images with more randomness."}},inferenceSteps:{label:"Inference Steps",class:NumberInputView,config:{min:5,max:250,step:1,value:null,tooltip:"How many steps to take during primary inference, larger values take longer to process."}}},Inference:{strength:{label:"Denoising Strength",class:FloatInputView,config:{min:0,max:1,step:.01,value:.8,config:"How much of the input image to replace with new information. A value of 1.0 represents total input image destruction, and 0.0 represents no image modifications being made."}}},Control:{controlnet:{label:"ControlNet",class:ControlNetInputView},conditioningScale:{label:"Conditioning Scale",class:FloatInputView,config:{min:0,max:1,step:.01,value:1,config:"How closely to follow ControlNet's influence."}},processControlImage:{label:"Process Image for ControlNet",class:CheckboxInputView,config:{value:!0,tooltip:"When checked, the image will be processed through the appropriate edge detection algorithm for the ControlNet. Only uncheck this if your image has already been processed through edge detection."}}},"Color Space":{colorSpace:{label:"Input Image Color Space",class:ImageColorSpaceInputView}}};static fieldSetConditions={Prompts:e=>e.infer||e.inpaint||e.control,Tweaks:e=>e.infer||e.inpaint||e.control,Inference:e=>e.infer,Control:e=>e.control,"Color Space":e=>e.control&&-1!==["mlsd","hed","pidi","scribble","line","anime"].indexOf(e.controlnet)&&!1===e.processControlImage};static autoSubmit=!0;static className="image-options-form-view"}class ImageEditorImageNodeView extends ImageEditorScribbleNodeView{static allFitModes=["actual","stretch","cover","contain"];static allAnchorModes=["top-left","top-center","top-right","center-left","center-center","center-right","bottom-left","bottom-center","bottom-right"];static scribbleButtons=["erase","shape","clear","increase","decrease"];static className="image-editor-image-node-view";static nodeButtons={...ImageEditorScribbleNodeView.nodeButtons,"mirror-x":{icon:"fa-solid fa-left-right",tooltip:"Mirror the image horizontally.",callback:function(){this.mirrorHorizontally()}},"mirror-y":{icon:"fa-solid fa-up-down",tooltip:"Mirror the image vertically.",callback:function(){this.mirrorVertically()}},"rotate-clockwise":{icon:"fa-solid fa-rotate-right",tooltip:"Rotate the image clockwise by 90 degrees.",callback:function(){this.rotateClockwise()}},"rotate-counter-clockwise":{icon:"fa-solid fa-rotate-left",tooltip:"Rotate the image counter-clockwise by 90 degrees.",callback:function(){this.rotateCounterClockwise()}}};static optionsFormView=ImageEditorImageNodeOptionsFormView;constructor(e,t,i,o,n,a,s){i instanceof ImageView&&(i=new BackgroundImageView(i.config,i.src)),super(e,t,null,o,n,a,s),this.scribbleView=this.content,this.content=i,this.scribbleView.hide()}async updateOptions(e){if(super.updateOptions(e),this.updateFit(e.fit),this.updateAnchor(e.anchor),this.infer=e.infer,this.control=e.control,this.inpaint=e.inpaint,this.strength=e.strength,this.controlnet=e.controlnet,this.conditioningScale=e.conditioningScale,this.processControlImage=e.processControlImage,void 0!==this.node){let e=this.node.find("enfugue-node-header");if(this.inpaint){this.scribbleView.show();for(let t of this.constructor.scribbleButtons)e.find(`.node-button-${t}`).show()}else{this.scribbleView.hide();for(let t of this.constructor.scribbleButtons)e.find(`.node-button-${t}`).hide()}}}async updateFit(e){this.fit=e;let t=await this.getContent();t.fit=e;for(let e of this.constructor.allFitModes)t.removeClass(`fit-${e}`);isEmpty(e)||t.addClass(`fit-${e}`)}async updateAnchor(e){this.anchor=e;let t=await this.getContent();for(let e of this.constructor.allAnchorModes)t.removeClass(`anchor-${e}`);isEmpty(e)||t.addClass(`anchor-${e}`)}async build(){let e=await super.build();e.find("enfugue-node-contents").append(await this.scribbleView.getNode());let t=e.find("enfugue-node-header");for(let e of this.constructor.scribbleButtons)t.find(`.node-button-${e}`).hide();return e}mirrorHorizontally(){return this.content.mirrorHorizontally()}mirrorVertically(){return this.content.mirrorVertically()}rotateClockwise(){return this.content.rotateClockwise()}rotateCounterClockwise(){return this.content.rotateCounterClockwise()}getState(){let e=super.getState();return e.scribbleSrc=this.scribbleView.src,e.src=this.content.src,e.anchor=this.anchor||null,e.fit=this.fit||null,e.infer=this.infer||!1,e.control=this.control||!1,e.inpaint=this.inpaint||!1,e.strength=this.strength||.8,e.controlnet=this.controlnet||null,e.colorSpace=this.colorSpace||"invert",e.conditioningScale=this.conditioningScale||1,e.processControlImage=!1!==this.processControlImage,e.removeBackground=!0===this.removeBackground,e.scaleToModelSize=!0===this.scaleToModelSize,e}async setState(e){if(await this.setContent(new BackgroundImageView(this.config,e.src)),await this.updateAnchor(e.anchor),await this.updateFit(e.fit),e.inpaint){let t=new Image;t.onload=()=>{if(this.scribbleView.setMemory(t),this.scribbleView.show(),void 0!==this.node){let e=this.node.find("enfugue-node-header");for(let t of this.constructor.scribbleButtons)e.find(`.node-button-${t}`).show()}},t.src=e.scribbleSrc}else if(this.scribbleView.clearMemory(),this.scribbleView.hide(),void 0!==this.node){let e=this.node.find("enfugue-node-header");for(let t of this.constructor.scribbleButtons)e.find(`.node-button-${t}`).hide()}await super.setState({...e,src:null})}static getDefaultState(){return{classname:this.name,inpaint:!1,control:!1,inpaint:!1,inferenceSteps:null,guidanceScale:null,strength:.8,processControlImage:!0,colorSpace:"invert",conditioningScale:1,removeBackground:!1,scaleToModelSize:!1}}}export{ControlNetInputView,ImageAnchorInputView,ImageFitInputView,ImageColorSpaceInputView,ImageEditorImageNodeView,ImageEditorImageNodeOptionsFormView};
