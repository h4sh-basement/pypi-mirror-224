import os
import sys
import ssl
import time
import uuid
import sanic
import pickle
import hashlib
import sqlite3
import asyncio
import aiohttp
import mimetypes

APP = sanic.Sanic('buckets')
APP.config.KEEP_ALIVE_TIMEOUT = 300


class SQLite():
    def __init__(self):
        path = os.path.join('buckets', 'db.sqlite3')
        if not os.path.isfile(path):
            tmp = os.path.join('buckets', str(uuid.uuid4()))

            db = sqlite3.connect(tmp)
            db.execute('''create table paxos(
                          bucket       text,
                          key          text,
                          version      unsigned int,
                          promised_seq unsigned int,
                          accepted_seq unsigned int,
                          value        text)''')
            db.execute('create unique index i0 on paxos(bucket,key,version)')
            db.commit()

            os.replace(tmp, path)

        SQLite.db = sqlite3.connect(path)

    def commit(self):
        SQLite.db.commit()

    def __call__(self, query, *args):
        return SQLite.db.execute(query, args).fetchall()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, exc_traceback):
        SQLite.db.rollback()


@APP.post('/version/<bucket:str>/<key:str>')
async def VERSION(request, bucket, key):
    with SQLite() as sql:
        rows = sql('''select max(version) from paxos
                      where bucket=? and key=? and
                            (accepted_seq>0 or accepted_seq is null)
                   ''', bucket, key)

    return response(max(BLOBStore(bucket).version(key),
                        rows[0][0] if rows[0][0] is not None else 0))


async def max_version(bucket, key):
    res = await rpc('version/{}/{}'.format(bucket, key))
    if CONF.quorum > len(res):
        raise sanic.exceptions.BadRequest('NO_MAX_VERSION_QUORUM')

    return max([pickle.loads(obj) for obj in res.values()])


@APP.post('/<phase:str>/<db:str>/<key:str>/<version:int>/<proposal_seq:int>')
async def paxos_server(request, phase, db, key, version, proposal_seq):
    if request.transport.get_extra_info('peercert') is None:
        raise sanic.exceptions.Unauthorized('INVALID_CERTIFICATE')

    with SQLite() as sql:
        # This value is already learned. Remove any leftovers from the table
        if BLOBStore(db).load_kv(key, version) is not None:
            sql('delete from paxos where bucket=? and key=? and version=?',
                db, key, version)
            sql.commit()
            raise sanic.exceptions.BadRequest('ALREADY_LEARNED')

        # Paxos begins here
        sql('insert or ignore into paxos values(?,?,?,0,0,null)',
            db, key, version)

        _, _, _, promised_seq, accepted_seq, value = sql(
            'select * from paxos where bucket=? and key=? and version=?',
            db, key, version)[0]

        # Standard paxos protocol PROMISE phase
        if 'promise' == phase and proposal_seq > promised_seq:
            sql('''update paxos set promised_seq=?
                   where bucket=? and key=? and version=?
                ''', proposal_seq, db, key, version)
            sql.commit()

            return response([accepted_seq, value])

        # Standard paxos protocol ACCEPT phase
        if 'accept' == phase and proposal_seq == promised_seq:
            sql('''update paxos set accepted_seq=?, value=?
                   where bucket=? and key=? and version=?
                ''',
                proposal_seq, pickle.loads(request.body), db, key, version)
            sql.commit()

            return response('OK')

        # Paxos protocol does not include this phase.
        # If a value for the key is accepted by a majority, it is learned.
        # Our paxos client, after a successful accept phase, asks participating
        # nodes to mark the row as final.
        if 'learn' == phase and promised_seq == accepted_seq == proposal_seq:
            BLOBStore(db).move(value, key, version)
            sql('delete from paxos where bucket=? and key=? and version=?',
                db, key, version)
            sql.commit()

            return response('OK')

    raise sanic.exceptions.BadRequest('UNKNOWN')


async def paxos_client(bucket, key, version, value=None):
    # paxos seq is an integer in the following format - YYYYmmddHHMMSS
    # This would increase monotonically. Even if same seq is generated by
    # more than one instances of paxos rounds, protocol handles it and rejects
    # the later round (as proposal_seq should be GREATER than the promised_seq)
    url = '{{}}/{}/{}/{}/{}'.format(
        bucket, key, version, time.strftime('%Y%m%d%H%M%S'))

    res = await rpc(url.format('promise'))
    res = [pickle.loads(obj) for obj in res.values()]
    if CONF.quorum > len(res):
        return dict(bucket=bucket, key=key, version=version,
                    status='NO_PROMISE_QUORUM')

    # Find out the accepted value with the highest accepted_seq
    proposal = (0, value)
    for accepted_seq, val in res:
        if accepted_seq > proposal[0]:
            proposal = (accepted_seq, val)

    if proposal[1] is None:
        return dict(bucket=bucket, key=key, version=version,
                    status='CANT_SET_NONE_VALUE')

    res = await rpc(url.format('accept'), pickle.dumps(proposal[1]))
    if CONF.quorum > len(res):
        return dict(bucket=bucket, key=key, version=version, value=proposal[1],
                    status='NO_ACCEPT_QUORUM')

    await rpc(url.format('learn'))

    return dict(bucket=bucket, key=key, version=version, value=proposal[1],
                status='OK' if 0 == proposal[0] else 'CONFLICT')


class BLOBStore():
    def __init__(self, bucket=''):
        h = hashlib.sha256(bucket.encode()).hexdigest()
        self.kv_path = os.path.join('buckets', 'data', h[0:3], h[3:6], bucket)
        self.tmp_path = os.path.join(self.kv_path, 'tmp')

    def dump(self, path, blob):
        os.makedirs(self.tmp_path, exist_ok=True)
        os.makedirs(os.path.dirname(path), exist_ok=True)

        tmppath = os.path.join(self.tmp_path, str(uuid.uuid4()) + '.tmp')
        with open(tmppath, 'wb') as fd:
            fd.write(blob)
        os.replace(tmppath, path)

    def load(self, path):
        if os.path.isfile(path):
            with open(path, 'rb') as fd:
                return fd.read()

    def dump_tmp(self, filename, blob):
        self.dump(os.path.join(self.tmp_path, filename), blob)

    def move(self, tmp, key, version):
        h = hashlib.sha256(key.encode()).hexdigest()
        dst = os.path.join(self.kv_path, h[0:3], h[3:6], key, str(version))

        if not os.path.isfile(dst):
            os.makedirs(os.path.dirname(dst), exist_ok=True)
            os.replace(os.path.join(self.tmp_path, tmp), dst)

    def load_kv(self, key, version):
        h = hashlib.sha256(key.encode()).hexdigest()
        path = os.path.join(self.kv_path, h[0:3], h[3:6], key, str(version))

        return self.load(path)

    def dump_kv(self, key, version, blob):
        h = hashlib.sha256(key.encode()).hexdigest()
        path = os.path.join(self.kv_path, h[0:3], h[3:6], key, str(version))

        self.dump(path, blob)

    def version(self, key):
        h = hashlib.sha256(key.encode()).hexdigest()
        path = os.path.join(self.kv_path, h[0:3], h[3:6], key)

        files = []
        if os.path.isdir(path):
            files = [int(f) for f in os.listdir(path) if f.isdigit()]

        return max(files) if files else 0


@APP.post('/<guid:uuid>')
async def WRITE_BLOB(request, guid):
    if request.transport.get_extra_info('peercert') is None:
        raise sanic.exceptions.Unauthorized('INVALID_CERTIFICATE')

    return response(BLOBStore().dump_tmp(str(guid), request.body))


async def write_blob(blob):
    guid = str(uuid.uuid4())
    res = await rpc('{}'.format(guid), blob)
    if CONF.quorum > len(res):
        raise sanic.exceptions.BadRequest('NO_POST_BLOB_QUORUM')

    return guid


@APP.put('/<bucket:str>')
async def APPEND_LOG(request, bucket):
    if not hasattr(APPEND_LOG, 'lock'):
        APPEND_LOG.lock = asyncio.Lock()
        APPEND_LOG.batch = dict(q=list())

    my_batch = APPEND_LOG.batch
    my_batch['q'].append(request.body)

    async with APPEND_LOG.lock:
        if my_batch is APPEND_LOG.batch:
            APPEND_LOG.batch = dict(q=list())

            guid = await write_blob(b''.join(my_batch.pop('q')))
            version = await max_version(bucket, bucket)

            while 'result' not in my_batch:
                result = await paxos_client(bucket, bucket, version+1, guid)
                if 'OK' != result['status']:
                    await asyncio.sleep(1)
                    version += 1

                my_batch['result'] = result

        return sanic.response.json(my_batch['result'])


@APP.put('/<bucket:str>/<key:str>/<version:int>')
async def WRITE_KV(request, bucket, key, version):
    if '127.0.0.1' != request.ip:
        raise sanic.exceptions.Unauthorized('UNAUTHORIZED_IP')

    if key == bucket:
        raise sanic.exceptions.Unauthorized('RESERVED_KEY_NAME')

    return sanic.response.json(await paxos_client(
        bucket, key, version, await write_blob(request.body)))


@APP.post('/<bucket:str>/<key:str>/<version:int>')
async def READ_KV(request, bucket, key, version):
    blob = BLOBStore(bucket).load_kv(key, version)

    if blob is None:
        raise sanic.exceptions.NotFound('NOT_FOUND')

    return sanic.response.raw(blob)


@APP.get('/<bucket:str>/<key:str>/<version:int>')
async def GET(request, bucket, key, version):
    store = BLOBStore(bucket)

    headers = {'x-bucket': bucket, 'x-key': key, 'x-version': version}
    headers['content-type'] = mimetypes.guess_type(key)[0]

    blob = store.load_kv(key, version)
    if blob is not None:
        return sanic.response.raw(blob, headers=headers)

    await paxos_client(bucket, key, version)

    for srv in CONF.nodes:
        blob = store.load_kv(key, version)
        if blob is not None:
            return sanic.response.raw(blob, headers=headers)

        res = await rpc('{}/{}/{}'.format(bucket, key, version), servers=[srv])
        if res:
            store.dump_kv(key, version, list(res.values())[0])

    raise sanic.exceptions.NotFound('NOT_FOUND')


@APP.get('/<bucket:str>/<key:str>')
async def GET_VALUE(request, bucket, key):
    return await GET(request, bucket, key, await max_version(bucket, key))


@APP.get('/<bucket:str>/<seq:int>')
async def GET_LOG(request, bucket, seq):
    return await GET(request, bucket, bucket, seq)


@APP.get('/<bucket:str>')
async def GET_LATEST_LOG(request, bucket):
    return await GET_VALUE(request, bucket, bucket)


def response(obj):
    return sanic.response.raw(pickle.dumps(obj))


async def rpc(url, data=b'', servers=None):
    servers = CONF.nodes if servers is None else servers

    if not hasattr(rpc, 'session'):
        SSL = ssl.create_default_context(
            cafile='self_signed.pem',
            purpose=ssl.Purpose.SERVER_AUTH)
        SSL.load_cert_chain('self_signed.pem', 'self_signed.pem')
        SSL.verify_mode = ssl.CERT_REQUIRED

        rpc.session = aiohttp.ClientSession(
            connector=aiohttp.TCPConnector(ssl=SSL))

    responses = await asyncio.gather(
        *[asyncio.ensure_future(rpc.session.post(
            'https://{}/{}'.format(srv, url), data=data)) for srv in servers],
        return_exceptions=True)

    result = dict()
    for s, r in zip(servers, responses):
        if type(r) is aiohttp.client_reqrep.ClientResponse:
            if 200 == r.status:
                octets = await r.read()
                if len(octets) == int(r.headers['content-length']):
                    result[s] = await r.read()

    return result


class CONF:
    nodes = None
    quorum = None


if '__main__' == __name__:
    HOST, PORT = sys.argv[1].split(':')

    CONF.nodes = set(sys.argv[1:])
    CONF.quorum = int((len(CONF.nodes)/2)+1)

    SSL = ssl.create_default_context(
        cafile='self_signed.pem',
        purpose=ssl.Purpose.CLIENT_AUTH)
    SSL.load_cert_chain('self_signed.pem', 'self_signed.pem')
    SSL.verify_mode = ssl.CERT_OPTIONAL

    APP.run(HOST, int(PORT), single_process=True, access_log=True, ssl=SSL)
