Metadata-Version: 2.1
Name: vec-cache
Version: 0.1.0
Summary: 
License: MIT
Author: kaz
Author-email: kaz.j11@gmail.com
Requires-Python: >=3.9,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Dist: faiss-cpu (>=1.7.4,<2.0.0)
Requires-Dist: numpy (>=1.25.2,<2.0.0)
Requires-Dist: openai (>=0.27.8,<0.28.0)
Requires-Dist: python-dotenv (>=1.0.0,<2.0.0)
Description-Content-Type: text/markdown

Sure! Below is a base `README.md` for your Python package:

---

# VecCache

VecCache is a Python package that provides an easy interface to cache embeddings of texts using OpenAI's API and allows for fast similarity searches over the cached embeddings.

## Features

- Utilize OpenAI's API to generate text embeddings.
- Cache the embeddings efficiently using `faiss`.
- Quick similarity searches over the cached embeddings.

## Installation

```bash
pip install vec_cache
```

> Note: You need to have an OpenAI API key to use this package.

## Usage

### Basic Usage

```python
from vec_cache import VecCache

# Initialize the cache with your OpenAI API key. If openai_api_key is not provided, .env or environment variable is loaded.
cache = VecCache(ttl=3600, openai_api_key="YOUR_OPENAI_API_KEY")

# Store a text in the cache
cache.store("Hello, World!")

# Search for the most similar text in the cache
result = cache.search("Hi, World!")
print(result)  # Outputs: "Hello, World!"
```

### Storing with Precomputed Vectors

If you have precomputed vectors, you can store them directly:

```python
vector = [0.1, 0.2, ...]  # Some precomputed vector
cache.store_with_vector("Some text", vector)
```

### Searching with Distance

If you wish to obtain the distance along with the result:

```python
result, distance = cache.search("Hi, World!", return_with_distance=True)
print(result)   # Outputs: "Hello, World!"
print(distance) # Outputs the L2 distance
```

## Configuration

`VecCache` accepts the following parameters:

- `ttl`: Time to live for cached vectors.
- `openai_api_key`: Your OpenAI API key.
- `embedding_model_name`: Name of the OpenAI embedding model. Default is "text-embedding-ada-002".
- `vector_size`: Size of the vector. Default is 1536.

## Contributions

We welcome contributions! Please submit a pull request or open an issue if you'd like to improve the package.

## License

This project is licensed under the MIT License.

---

Feel free to customize the content based on your package's details and specific requirements.
