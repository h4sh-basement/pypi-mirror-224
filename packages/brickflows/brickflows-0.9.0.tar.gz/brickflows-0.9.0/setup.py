# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['brickflow',
 'brickflow.bundles',
 'brickflow.cli',
 'brickflow.codegen',
 'brickflow.context',
 'brickflow.engine',
 'brickflow.hints',
 'brickflow.resolver',
 'brickflow.tf',
 'brickflow.tf.databricks',
 'brickflow.tf.databricks._jsii',
 'brickflow.tf.databricks.aws_s3_mount',
 'brickflow.tf.databricks.azure_adls_gen1_mount',
 'brickflow.tf.databricks.azure_adls_gen2_mount',
 'brickflow.tf.databricks.azure_blob_mount',
 'brickflow.tf.databricks.catalog',
 'brickflow.tf.databricks.cluster',
 'brickflow.tf.databricks.cluster_policy',
 'brickflow.tf.databricks.data_databricks_aws_assume_role_policy',
 'brickflow.tf.databricks.data_databricks_aws_bucket_policy',
 'brickflow.tf.databricks.data_databricks_aws_crossaccount_policy',
 'brickflow.tf.databricks.data_databricks_catalogs',
 'brickflow.tf.databricks.data_databricks_cluster',
 'brickflow.tf.databricks.data_databricks_cluster_policy',
 'brickflow.tf.databricks.data_databricks_clusters',
 'brickflow.tf.databricks.data_databricks_current_user',
 'brickflow.tf.databricks.data_databricks_dbfs_file',
 'brickflow.tf.databricks.data_databricks_dbfs_file_paths',
 'brickflow.tf.databricks.data_databricks_directory',
 'brickflow.tf.databricks.data_databricks_group',
 'brickflow.tf.databricks.data_databricks_instance_pool',
 'brickflow.tf.databricks.data_databricks_job',
 'brickflow.tf.databricks.data_databricks_jobs',
 'brickflow.tf.databricks.data_databricks_mws_credentials',
 'brickflow.tf.databricks.data_databricks_mws_workspaces',
 'brickflow.tf.databricks.data_databricks_node_type',
 'brickflow.tf.databricks.data_databricks_notebook',
 'brickflow.tf.databricks.data_databricks_notebook_paths',
 'brickflow.tf.databricks.data_databricks_schemas',
 'brickflow.tf.databricks.data_databricks_service_principal',
 'brickflow.tf.databricks.data_databricks_service_principals',
 'brickflow.tf.databricks.data_databricks_share',
 'brickflow.tf.databricks.data_databricks_shares',
 'brickflow.tf.databricks.data_databricks_spark_version',
 'brickflow.tf.databricks.data_databricks_sql_warehouse',
 'brickflow.tf.databricks.data_databricks_sql_warehouses',
 'brickflow.tf.databricks.data_databricks_tables',
 'brickflow.tf.databricks.data_databricks_user',
 'brickflow.tf.databricks.data_databricks_views',
 'brickflow.tf.databricks.data_databricks_zones',
 'brickflow.tf.databricks.dbfs_file',
 'brickflow.tf.databricks.directory',
 'brickflow.tf.databricks.entitlements',
 'brickflow.tf.databricks.external_location',
 'brickflow.tf.databricks.git_credential',
 'brickflow.tf.databricks.global_init_script',
 'brickflow.tf.databricks.grants',
 'brickflow.tf.databricks.group',
 'brickflow.tf.databricks.group_instance_profile',
 'brickflow.tf.databricks.group_member',
 'brickflow.tf.databricks.group_role',
 'brickflow.tf.databricks.instance_pool',
 'brickflow.tf.databricks.instance_profile',
 'brickflow.tf.databricks.ip_access_list',
 'brickflow.tf.databricks.job',
 'brickflow.tf.databricks.library',
 'brickflow.tf.databricks.metastore',
 'brickflow.tf.databricks.metastore_assignment',
 'brickflow.tf.databricks.metastore_data_access',
 'brickflow.tf.databricks.mlflow_experiment',
 'brickflow.tf.databricks.mlflow_model',
 'brickflow.tf.databricks.mlflow_webhook',
 'brickflow.tf.databricks.model_serving',
 'brickflow.tf.databricks.mount',
 'brickflow.tf.databricks.mws_credentials',
 'brickflow.tf.databricks.mws_customer_managed_keys',
 'brickflow.tf.databricks.mws_log_delivery',
 'brickflow.tf.databricks.mws_networks',
 'brickflow.tf.databricks.mws_permission_assignment',
 'brickflow.tf.databricks.mws_private_access_settings',
 'brickflow.tf.databricks.mws_storage_configurations',
 'brickflow.tf.databricks.mws_vpc_endpoint',
 'brickflow.tf.databricks.mws_workspaces',
 'brickflow.tf.databricks.notebook',
 'brickflow.tf.databricks.obo_token',
 'brickflow.tf.databricks.permission_assignment',
 'brickflow.tf.databricks.permissions',
 'brickflow.tf.databricks.pipeline',
 'brickflow.tf.databricks.provider',
 'brickflow.tf.databricks.provider_resource',
 'brickflow.tf.databricks.recipient',
 'brickflow.tf.databricks.repo',
 'brickflow.tf.databricks.schema',
 'brickflow.tf.databricks.secret',
 'brickflow.tf.databricks.secret_acl',
 'brickflow.tf.databricks.secret_scope',
 'brickflow.tf.databricks.service_principal',
 'brickflow.tf.databricks.service_principal_role',
 'brickflow.tf.databricks.service_principal_secret',
 'brickflow.tf.databricks.share',
 'brickflow.tf.databricks.sql_alert',
 'brickflow.tf.databricks.sql_dashboard',
 'brickflow.tf.databricks.sql_endpoint',
 'brickflow.tf.databricks.sql_global_config',
 'brickflow.tf.databricks.sql_permissions',
 'brickflow.tf.databricks.sql_query',
 'brickflow.tf.databricks.sql_visualization',
 'brickflow.tf.databricks.sql_widget',
 'brickflow.tf.databricks.storage_credential',
 'brickflow.tf.databricks.table',
 'brickflow.tf.databricks.token',
 'brickflow.tf.databricks.user',
 'brickflow.tf.databricks.user_instance_profile',
 'brickflow.tf.databricks.user_role',
 'brickflow.tf.databricks.workspace_conf',
 'brickflow.tf.random',
 'brickflow.tf.random._jsii',
 'brickflow.tf.random.id',
 'brickflow.tf.random.integer',
 'brickflow.tf.random.password',
 'brickflow.tf.random.pet',
 'brickflow.tf.random.provider',
 'brickflow.tf.random.shuffle',
 'brickflow.tf.random.string_resource',
 'brickflow.tf.random.uuid',
 'brickflow_plugins',
 'brickflow_plugins.airflow',
 'brickflow_plugins.airflow.context',
 'brickflow_plugins.airflow.operators',
 'brickflow_plugins.airflow.vendor',
 'brickflow_plugins.databricks',
 'brickflow_plugins.secrets']

package_data = \
{'': ['*']}

install_requires = \
['Jinja2==3.1.2',
 'click>=8.1.3,<9.0.0',
 'databricks-sdk>=0.1.8,<1.0.0',
 'networkx==3.1',
 'pendulum==2.1.2',
 'pluggy>=1.0.0,<2.0.0',
 'pydantic>=1.10.9,<2.0.0',
 'python-decouple==3.8',
 'pyyaml>=6.0.0,<7.0.0',
 'requests>=2.28.2,<3.0.0']

extras_require = \
{'all': ['cdktf>=0.17.3,<0.18.0'], 'deploy': ['cdktf>=0.17.3,<0.18.0']}

entry_points = \
{'console_scripts': ['bf = brickflow.cli:cli', 'brickflow = brickflow.cli:cli']}

setup_kwargs = {
    'name': 'brickflows',
    'version': '0.9.0',
    'description': 'Deploy scalable workflows to databricks using python',
    'long_description': '# Brickflow\n\n[//]: # ([![CodeQL]&#40;https://github.com/Nike-Inc/brickflow/actions/workflows/codeql-analysis.yml/badge.svg&#41;]&#40;https://github.com/Nike-Inc/brickflow/actions/workflows/codeql-analysis.yml&#41;)\n[![build](https://github.com/Nike-Inc/brickflow/actions/workflows/onpush.yml/badge.svg)](https://github.com/Nike-Inc/brickflow/actions/workflows/onpush.yml)\n[![codecov](https://codecov.io/gh/Nike-Inc/brickflow/branch/main/graph/badge.svg)](https://codecov.io/gh/Nike-Inc/brickflow)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n[![Checked with mypy](http://www.mypy-lang.org/static/mypy_badge.svg)](http://mypy-lang.org/)\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\n<p align="center">\nBrickFlow is specifically designed to enable the development of Databricks workflows using Python, streamlining the \nprocess through a command-line interface (CLI) tool.\n\n<img src="./docs/img/bf_logo_1.png" width="400" height="400">\n\n---\n\n### Documentation\n\nBrickflow documentation can be found [here]().\n\n### Contributors\n\nThanks to all the [contributors](CONTRIBUTORS.md) who have helped ideate, develop and bring Brickflow to its current state. \n\n### Contributing\n\nWe\'re delighted that you\'re interested in contributing to our project! To get started, \nplease carefully read and follow the guidelines provided in our [contributing](CONTRIBUTING.md) document.\n',
    'author': 'Ashok Singamaneni, Sriharsha Tikkireddy',
    'author_email': 'None',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/Nike-Inc/brickflow',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'extras_require': extras_require,
    'entry_points': entry_points,
    'python_requires': '>=3.8,<4.0',
}


setup(**setup_kwargs)
