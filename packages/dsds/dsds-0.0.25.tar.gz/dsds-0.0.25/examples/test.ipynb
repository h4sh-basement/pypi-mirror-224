{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import dsds.metrics as me\n",
    "import dsds.prescreen as ps\n",
    "import dsds.sample as sa\n",
    "import dsds.fs as fs\n",
    "import dsds.transform as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/train.csv\").with_columns(\n",
    "    pl.lit(1).alias(\"feature_1\"),\n",
    "    pl.lit(2).alias(\"feature_2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsds._rust import rs_cnt_vectorizer, rs_ref_table, rs_snowball_stem, rs_levenshtein_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsds.text import get_ref_table\n",
    "\n",
    "ref = get_ref_table(df, \"Description\", min_dfreq=0.02, max_dfreq=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_ref_table(df, \"Description\", \"snowball\", 0.02, 0.95, 5000, 500).sort(\"ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsds.text as tt\n",
    "res = tt.tfidf_vectorizer(df, \"Description\", \"snowball\", 0.02, 0.95, 5000, 500, True)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "res = tt.tfidf_vectorizer(df, \"Description\", \"snowball\", 0.02, 0.95, 5000, 500, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsds._rust import rs_cnt_vectorizer, rs_ref_table, rs_snowball_stem, rs_levenshtein_dist\n",
    "import dsds.text as tt\n",
    "c = \"Ad Topic Line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "sw = list(stopwords.words('english'))\n",
    "corpus = df[\"Description\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.95, min_df=0.02, stop_words=sw)\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "cols = vectorizer.get_feature_names_out().tolist()\n",
    "df_words = pl.from_numpy(X, schema=cols)\n",
    "df_combined = pl.concat([df, df_words], how=\"horizontal\")\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined[\"city\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "corpus = ['this is the first document', 'this document is the second document', 'and this is the third one','is this the first document']\n",
    "vocabulary = ['this', 'document', 'first', 'is', 'second', 'the','and', 'one']\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)), ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "pipe['count'].transform(corpus).toarray()\n",
    "pipe['tfid'].idf_\n",
    "pipe.transform(corpus).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.transform(corpus).toarray() # .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe[\"count\"].get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(\"../data/advertising.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
