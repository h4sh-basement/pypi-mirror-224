Metadata-Version: 2.1
Name: dallm
Version: 0.0.6
Summary: Domain Adapted Language Model
Home-page: https://arcee.ai/
Author: Arcee
Author-email: jacob@arcee.ai
License: UNKNOWN
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: accelerate (==0.20.1)
Requires-Dist: datasets (==2.12.0)
Requires-Dist: langchain (==0.0.198)
Requires-Dist: openai (==0.27.8)
Requires-Dist: peft (==0.3.0)
Requires-Dist: transformers (==4.30.1)
Requires-Dist: trl (==0.4.6)
Provides-Extra: dev
Requires-Dist: black (==22.3.0) ; extra == 'dev'
Requires-Dist: flake8 ; extra == 'dev'
Requires-Dist: isort ; extra == 'dev'
Requires-Dist: pytest ; extra == 'dev'
Requires-Dist: twine ; extra == 'dev'
Requires-Dist: wheel ; extra == 'dev'

# Arcee

:tulip:	The open source alignment toolkit for finetuning and deploying LLMs :tulip:

## Finetuning Datasets

The Arcee toolkit contains routines for you to manage and generate finetuning datasets. The arcee toolkit supports supervised finetuning (SFT) aka intruction tuning. 

### ‚úçÔ∏è Instruction Set ‚úçÔ∏è

Instruction tuning datasets contain a series of prompt and completion examples.

Instruction sets can be loaded from a csv.

```
from arcee.data import InstructionSet
instruction_set = InstructionSet("./datasets/strip_api.csv")
```

Or downloaded from the Arcee platform

```
from arcee.data import InstructionSet
instruction_set = InstructionSet("https://app.arcee.ai/arcee/alpaca")
```

### Self-Instruct Generation

### Evolv-Instruct Genertation

### Explain-Instruct Generation


## Finetuning Models

### HuggingFace

```
from arcee.models import LM
from arcee.data import Instuctions

lm = LM("falcon30b")
instructions = Instructions("./datasets/stripe-api.json")
lm.train(instructions)

lm.predict("Place an order for the LLM-9000 product for 100 USD to the card 3007200039992000")
```

### OpenAI

### Cohere

### Together

### Mosaic ML

## LangChain Integration

```
from langchain import Arcee
#goes in llms/arcee.py

prompt_template = "Write a stripe API request for the following: {order}."

llm = Arcee(temperature=0)
llm_chain = LLMChain(
    llm=llm,
    prompt=PromptTemplate.from_template(prompt_template)
)
llm_chain("Place an order for the LLM-9000 product for 100 USD to the card 3007200039992000")
```

## Domain Pretraining

Coming soon!

## üóª Arcee Platform üóª

Arcee offers a platform for managing your proprietary language models in production. We offer a version of our platform hosted in our cloud as well as a deployable version that you can take on prem.

### Authenticaiton

To use the arcee platform, visit https://app.arcee.com/api-settings and `export ARCEE_API_KEY=*******` in your environment.

### Dataset Managemnt

View, search, and edit datasets. 

```
instruction_set.upload("project-name")
```

### Hosted Training

### Hosted Inference

### Lifecycle Management






